

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Translate &mdash; MAMMOTH  documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/language_data.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]]}})</script>
        <script src="https://unpkg.com/mermaid@8.4.8/dist/mermaid.min.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/theme_overrides.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Server" href="server.html" />
    <link rel="prev" title="Train" href="train.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> MAMMOTH
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../main.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quickstart.html">Quickstart</a></li>
<li class="toctree-l1"><a class="reference internal" href="../CONTRIBUTING.html">Contributors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ref.html">References</a></li>
</ul>
<p class="caption"><span class="caption-text">Frequently Asked Questions</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../FAQ.html">About MAMMOTH</a></li>
<li class="toctree-l1"><a class="reference internal" href="../FAQ.html#mammoth-and-opennmt">MAMMOTH and OpenNMT</a></li>
</ul>
<p class="caption"><span class="caption-text">MAMMOTH features</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../modular_model.html">Modular Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../config_config.html">Config-config tool</a></li>
<li class="toctree-l1"><a class="reference internal" href="../attention_bridges.html">Attention Bridge</a></li>
</ul>
<p class="caption"><span class="caption-text">Tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../install.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../prepare_data.html">Prepare Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples/train_mammoth_101.html">Train your MAMMOTH model 101</a></li>
</ul>
<p class="caption"><span class="caption-text">Scripts</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="build_vocab.html">Build Vocab</a></li>
<li class="toctree-l1"><a class="reference internal" href="train.html">Train</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Translate</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#Configuration">Configuration</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Model">Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Data">Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Beam Search">Beam Search</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Random Sampling">Random Sampling</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Reproducibility">Reproducibility</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Penalties">Penalties</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Decoding tricks">Decoding tricks</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Logging">Logging</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Efficiency">Efficiency</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Transform/Denoising AE">Transform/Denoising AE</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Transform/Filter">Transform/Filter</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Transform/Filter_repeat1">Transform/Filter</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Transform/Filter_repeat2">Transform/Filter</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Transform/Filter_repeat3">Transform/Filter</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Transform/Filter_repeat4">Transform/Filter</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Transform/InferFeats">Transform/InferFeats</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Transform/SwitchOut">Transform/SwitchOut</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Transform/Token_Drop">Transform/Token_Drop</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Transform/Token_Mask">Transform/Token_Mask</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Transform/Subword/Common">Transform/Subword/Common</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Transform/Subword/ONMTTOK">Transform/Subword/ONMTTOK</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Source and Target Languages">Source and Target Languages</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="server.html">Server</a></li>
</ul>
<p class="caption"><span class="caption-text">API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../mammoth.html">Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mammoth.modules.html">Modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mammoth.translation.html">Translation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mammoth.translate.translation_server.html">Server</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mammoth.inputters.html">Data Loaders</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MAMMOTH</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
      <li>Translate</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/options/translate.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="translate">
<h1>Translate<a class="headerlink" href="#translate" title="Permalink to this headline">Â¶</a></h1>
<p><p>translate.py</p>
</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">usage</span><span class="p">:</span> <span class="n">translate</span><span class="o">.</span><span class="n">py</span> <span class="p">[</span><span class="o">-</span><span class="n">h</span><span class="p">]</span> <span class="p">[</span><span class="o">-</span><span class="n">config</span> <span class="n">CONFIG</span><span class="p">]</span> <span class="p">[</span><span class="o">-</span><span class="n">save_config</span> <span class="n">SAVE_CONFIG</span><span class="p">]</span> <span class="o">--</span><span class="n">model</span> <span class="n">MODEL</span> <span class="p">[</span><span class="n">MODEL</span> <span class="o">...</span><span class="p">]</span> <span class="p">[</span><span class="o">--</span><span class="n">fp32</span><span class="p">]</span> <span class="p">[</span><span class="o">--</span><span class="n">int8</span><span class="p">]</span> <span class="p">[</span><span class="o">--</span><span class="n">avg_raw_probs</span><span class="p">]</span> <span class="p">[</span><span class="o">--</span><span class="n">lang_pair</span> <span class="n">LANG_PAIR</span><span class="p">]</span>
                    <span class="p">[</span><span class="o">--</span><span class="n">data_type</span> <span class="n">DATA_TYPE</span><span class="p">]</span> <span class="o">--</span><span class="n">src</span> <span class="n">SRC</span> <span class="p">[</span><span class="o">-</span><span class="n">src_feats</span> <span class="n">SRC_FEATS</span><span class="p">]</span> <span class="p">[</span><span class="o">--</span><span class="n">tgt</span> <span class="n">TGT</span><span class="p">]</span> <span class="p">[</span><span class="o">--</span><span class="n">shard_size</span> <span class="n">SHARD_SIZE</span><span class="p">]</span> <span class="p">[</span><span class="o">--</span><span class="n">output</span> <span class="n">OUTPUT</span><span class="p">]</span> <span class="p">[</span><span class="o">--</span><span class="n">report_align</span><span class="p">]</span>
                    <span class="p">[</span><span class="o">--</span><span class="n">report_time</span><span class="p">]</span> <span class="p">[</span><span class="o">--</span><span class="n">beam_size</span> <span class="n">BEAM_SIZE</span><span class="p">]</span> <span class="p">[</span><span class="o">--</span><span class="n">ratio</span> <span class="n">RATIO</span><span class="p">]</span> <span class="p">[</span><span class="o">--</span><span class="n">random_sampling_topk</span> <span class="n">RANDOM_SAMPLING_TOPK</span><span class="p">]</span>
                    <span class="p">[</span><span class="o">--</span><span class="n">random_sampling_topp</span> <span class="n">RANDOM_SAMPLING_TOPP</span><span class="p">]</span> <span class="p">[</span><span class="o">--</span><span class="n">random_sampling_temp</span> <span class="n">RANDOM_SAMPLING_TEMP</span><span class="p">]</span> <span class="p">[</span><span class="o">--</span><span class="n">seed</span> <span class="n">SEED</span><span class="p">]</span>
                    <span class="p">[</span><span class="o">--</span><span class="n">length_penalty</span> <span class="p">{</span><span class="n">none</span><span class="p">,</span><span class="n">wu</span><span class="p">,</span><span class="n">avg</span><span class="p">}]</span> <span class="p">[</span><span class="o">--</span><span class="n">alpha</span> <span class="n">ALPHA</span><span class="p">]</span> <span class="p">[</span><span class="o">--</span><span class="n">coverage_penalty</span> <span class="p">{</span><span class="n">none</span><span class="p">,</span><span class="n">wu</span><span class="p">,</span><span class="n">summary</span><span class="p">}]</span> <span class="p">[</span><span class="o">--</span><span class="n">beta</span> <span class="n">BETA</span><span class="p">]</span> <span class="p">[</span><span class="o">--</span><span class="n">stepwise_penalty</span><span class="p">]</span>
                    <span class="p">[</span><span class="o">--</span><span class="n">min_length</span> <span class="n">MIN_LENGTH</span><span class="p">]</span> <span class="p">[</span><span class="o">--</span><span class="n">max_length</span> <span class="n">MAX_LENGTH</span><span class="p">]</span> <span class="p">[</span><span class="o">--</span><span class="n">max_sent_length</span><span class="p">]</span> <span class="p">[</span><span class="o">--</span><span class="n">block_ngram_repeat</span> <span class="n">BLOCK_NGRAM_REPEAT</span><span class="p">]</span>
                    <span class="p">[</span><span class="o">--</span><span class="n">ignore_when_blocking</span> <span class="n">IGNORE_WHEN_BLOCKING</span> <span class="p">[</span><span class="n">IGNORE_WHEN_BLOCKING</span> <span class="o">...</span><span class="p">]]</span> <span class="p">[</span><span class="o">--</span><span class="n">replace_unk</span><span class="p">]</span> <span class="p">[</span><span class="o">--</span><span class="n">ban_unk_token</span><span class="p">]</span>
                    <span class="p">[</span><span class="o">--</span><span class="n">phrase_table</span> <span class="n">PHRASE_TABLE</span><span class="p">]</span> <span class="p">[</span><span class="o">--</span><span class="n">log_file</span> <span class="n">LOG_FILE</span><span class="p">]</span> <span class="p">[</span><span class="o">--</span><span class="n">structured_log_file</span> <span class="n">STRUCTURED_LOG_FILE</span><span class="p">]</span>
                    <span class="p">[</span><span class="o">--</span><span class="n">log_file_level</span> <span class="p">{</span><span class="n">CRITICAL</span><span class="p">,</span><span class="n">ERROR</span><span class="p">,</span><span class="n">WARNING</span><span class="p">,</span><span class="n">INFO</span><span class="p">,</span><span class="n">DEBUG</span><span class="p">,</span><span class="n">NOTSET</span><span class="p">,</span><span class="mi">50</span><span class="p">,</span><span class="mi">40</span><span class="p">,</span><span class="mi">30</span><span class="p">,</span><span class="mi">20</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">0</span><span class="p">}]</span> <span class="p">[</span><span class="o">--</span><span class="n">verbose</span><span class="p">]</span> <span class="p">[</span><span class="o">--</span><span class="n">attn_debug</span><span class="p">]</span> <span class="p">[</span><span class="o">--</span><span class="n">align_debug</span><span class="p">]</span>
                    <span class="p">[</span><span class="o">--</span><span class="n">dump_beam</span> <span class="n">DUMP_BEAM</span><span class="p">]</span> <span class="p">[</span><span class="o">--</span><span class="n">n_best</span> <span class="n">N_BEST</span><span class="p">]</span> <span class="p">[</span><span class="o">--</span><span class="n">batch_size</span> <span class="n">BATCH_SIZE</span><span class="p">]</span> <span class="p">[</span><span class="o">--</span><span class="n">batch_type</span> <span class="p">{</span><span class="n">sents</span><span class="p">,</span><span class="n">tokens</span><span class="p">}]</span> <span class="p">[</span><span class="o">--</span><span class="n">gpu</span> <span class="n">GPU</span><span class="p">]</span>
                    <span class="p">[</span><span class="o">-</span><span class="n">transforms</span> <span class="p">{</span><span class="n">prefix</span><span class="p">,</span><span class="n">denoising</span><span class="p">,</span><span class="n">filtertoolong</span><span class="p">,</span><span class="n">filterwordratio</span><span class="p">,</span><span class="n">filterrepetitions</span><span class="p">,</span><span class="n">filterterminalpunct</span><span class="p">,</span><span class="n">filternonzeronumerals</span><span class="p">,</span><span class="n">filterfeats</span><span class="p">,</span><span class="n">inferfeats</span><span class="p">,</span><span class="n">switchout</span><span class="p">,</span><span class="n">tokendrop</span><span class="p">,</span><span class="n">tokenmask</span><span class="p">,</span><span class="n">sentencepiece</span><span class="p">,</span><span class="n">bpe</span><span class="p">,</span><span class="n">onmt_tokenize</span><span class="p">}</span> <span class="p">[{</span><span class="n">prefix</span><span class="p">,</span><span class="n">denoising</span><span class="p">,</span><span class="n">filtertoolong</span><span class="p">,</span><span class="n">filterwordratio</span><span class="p">,</span><span class="n">filterrepetitions</span><span class="p">,</span><span class="n">filterterminalpunct</span><span class="p">,</span><span class="n">filternonzeronumerals</span><span class="p">,</span><span class="n">filterfeats</span><span class="p">,</span><span class="n">inferfeats</span><span class="p">,</span><span class="n">switchout</span><span class="p">,</span><span class="n">tokendrop</span><span class="p">,</span><span class="n">tokenmask</span><span class="p">,</span><span class="n">sentencepiece</span><span class="p">,</span><span class="n">bpe</span><span class="p">,</span><span class="n">onmt_tokenize</span><span class="p">}</span> <span class="o">...</span><span class="p">]]</span>
                    <span class="p">[</span><span class="o">--</span><span class="n">permute_sent_ratio</span> <span class="n">PERMUTE_SENT_RATIO</span><span class="p">]</span> <span class="p">[</span><span class="o">--</span><span class="n">rotate_ratio</span> <span class="n">ROTATE_RATIO</span><span class="p">]</span> <span class="p">[</span><span class="o">--</span><span class="n">insert_ratio</span> <span class="n">INSERT_RATIO</span><span class="p">]</span> <span class="p">[</span><span class="o">--</span><span class="n">random_ratio</span> <span class="n">RANDOM_RATIO</span><span class="p">]</span>
                    <span class="p">[</span><span class="o">--</span><span class="n">mask_ratio</span> <span class="n">MASK_RATIO</span><span class="p">]</span> <span class="p">[</span><span class="o">--</span><span class="n">mask_length</span> <span class="p">{</span><span class="n">subword</span><span class="p">,</span><span class="n">word</span><span class="p">,</span><span class="n">span</span><span class="o">-</span><span class="n">poisson</span><span class="p">}]</span> <span class="p">[</span><span class="o">--</span><span class="n">poisson_lambda</span> <span class="n">POISSON_LAMBDA</span><span class="p">]</span> <span class="p">[</span><span class="o">--</span><span class="n">replace_length</span> <span class="p">{</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">}]</span>
                    <span class="p">[</span><span class="o">--</span><span class="n">denoising_objective</span> <span class="p">{</span><span class="n">bart</span><span class="p">,</span><span class="n">mass</span><span class="p">}]</span> <span class="p">[</span><span class="o">--</span><span class="n">src_seq_length</span> <span class="n">SRC_SEQ_LENGTH</span><span class="p">]</span> <span class="p">[</span><span class="o">--</span><span class="n">tgt_seq_length</span> <span class="n">TGT_SEQ_LENGTH</span><span class="p">]</span>
                    <span class="p">[</span><span class="o">--</span><span class="n">word_ratio_threshold</span> <span class="n">WORD_RATIO_THRESHOLD</span><span class="p">]</span> <span class="p">[</span><span class="o">--</span><span class="n">rep_threshold</span> <span class="n">REP_THRESHOLD</span><span class="p">]</span> <span class="p">[</span><span class="o">--</span><span class="n">rep_min_len</span> <span class="n">REP_MIN_LEN</span><span class="p">]</span> <span class="p">[</span><span class="o">--</span><span class="n">rep_max_len</span> <span class="n">REP_MAX_LEN</span><span class="p">]</span>
                    <span class="p">[</span><span class="o">--</span><span class="n">punct_threshold</span> <span class="n">PUNCT_THRESHOLD</span><span class="p">]</span> <span class="p">[</span><span class="o">--</span><span class="n">nonzero_threshold</span> <span class="n">NONZERO_THRESHOLD</span><span class="p">]</span> <span class="p">[</span><span class="o">--</span><span class="n">reversible_tokenization</span> <span class="p">{</span><span class="n">joiner</span><span class="p">,</span><span class="n">spacer</span><span class="p">}]</span>
                    <span class="p">[</span><span class="o">--</span><span class="n">prior_tokenization</span><span class="p">]</span> <span class="p">[</span><span class="o">-</span><span class="n">switchout_temperature</span> <span class="n">SWITCHOUT_TEMPERATURE</span><span class="p">]</span> <span class="p">[</span><span class="o">-</span><span class="n">tokendrop_temperature</span> <span class="n">TOKENDROP_TEMPERATURE</span><span class="p">]</span>
                    <span class="p">[</span><span class="o">-</span><span class="n">tokenmask_temperature</span> <span class="n">TOKENMASK_TEMPERATURE</span><span class="p">]</span> <span class="p">[</span><span class="o">-</span><span class="n">src_subword_model</span> <span class="n">SRC_SUBWORD_MODEL</span><span class="p">]</span> <span class="p">[</span><span class="o">-</span><span class="n">tgt_subword_model</span> <span class="n">TGT_SUBWORD_MODEL</span><span class="p">]</span>
                    <span class="p">[</span><span class="o">-</span><span class="n">src_subword_nbest</span> <span class="n">SRC_SUBWORD_NBEST</span><span class="p">]</span> <span class="p">[</span><span class="o">-</span><span class="n">tgt_subword_nbest</span> <span class="n">TGT_SUBWORD_NBEST</span><span class="p">]</span> <span class="p">[</span><span class="o">-</span><span class="n">src_subword_alpha</span> <span class="n">SRC_SUBWORD_ALPHA</span><span class="p">]</span>
                    <span class="p">[</span><span class="o">-</span><span class="n">tgt_subword_alpha</span> <span class="n">TGT_SUBWORD_ALPHA</span><span class="p">]</span> <span class="p">[</span><span class="o">-</span><span class="n">src_subword_vocab</span> <span class="n">SRC_SUBWORD_VOCAB</span><span class="p">]</span> <span class="p">[</span><span class="o">-</span><span class="n">tgt_subword_vocab</span> <span class="n">TGT_SUBWORD_VOCAB</span><span class="p">]</span>
                    <span class="p">[</span><span class="o">-</span><span class="n">src_vocab_threshold</span> <span class="n">SRC_VOCAB_THRESHOLD</span><span class="p">]</span> <span class="p">[</span><span class="o">-</span><span class="n">tgt_vocab_threshold</span> <span class="n">TGT_VOCAB_THRESHOLD</span><span class="p">]</span> <span class="p">[</span><span class="o">-</span><span class="n">src_subword_type</span> <span class="p">{</span><span class="n">none</span><span class="p">,</span><span class="n">sentencepiece</span><span class="p">,</span><span class="n">bpe</span><span class="p">}]</span>
                    <span class="p">[</span><span class="o">-</span><span class="n">tgt_subword_type</span> <span class="p">{</span><span class="n">none</span><span class="p">,</span><span class="n">sentencepiece</span><span class="p">,</span><span class="n">bpe</span><span class="p">}]</span> <span class="p">[</span><span class="o">-</span><span class="n">src_onmttok_kwargs</span> <span class="n">SRC_ONMTTOK_KWARGS</span><span class="p">]</span> <span class="p">[</span><span class="o">-</span><span class="n">tgt_onmttok_kwargs</span> <span class="n">TGT_ONMTTOK_KWARGS</span><span class="p">]</span>
                    <span class="p">[</span><span class="o">--</span><span class="n">src_prefix</span> <span class="n">SRC_PREFIX</span><span class="p">]</span> <span class="p">[</span><span class="o">--</span><span class="n">tgt_prefix</span> <span class="n">TGT_PREFIX</span><span class="p">]</span> <span class="o">--</span><span class="n">src_lang</span> <span class="n">SRC_LANG</span> <span class="o">--</span><span class="n">tgt_lang</span> <span class="n">TGT_LANG</span> <span class="o">--</span><span class="n">stack</span> <span class="n">STACK</span> <span class="p">[</span><span class="o">--</span><span class="n">output_model</span> <span class="n">OUTPUT_MODEL</span><span class="p">]</span>
</pre></div>
</div>
<div class="section" id="Configuration">
<h2>Configuration<a class="headerlink" href="#Configuration" title="Permalink to this headline">Â¶</a></h2>
<dl class="option-list">
<dt><kbd>-config, --config</kbd></dt>
<dd><p>Path of the main YAML config file.</p>
</dd>
<dt><kbd>-save_config, --save_config</kbd></dt>
<dd><p>Path where to save the config.</p>
</dd>
</dl>
</div>
<div class="section" id="Model">
<h2>Model<a class="headerlink" href="#Model" title="Permalink to this headline">Â¶</a></h2>
<dl class="option-list">
<dt><kbd>--model, -model</kbd></dt>
<dd><p>Path to model .pt file(s). Multiple models can be specified, for ensemble decoding.</p>
<p>Default: []</p>
</dd>
<dt><kbd>--fp32, -fp32</kbd></dt>
<dd><p>Force the model to be in FP32 because FP16 is very slow on GTX1080(ti).</p>
<p>Default: False</p>
</dd>
<dt><kbd>--int8, -int8</kbd></dt>
<dd><p>Enable dynamic 8-bit quantization (CPU only).</p>
<p>Default: False</p>
</dd>
<dt><kbd>--avg_raw_probs, -avg_raw_probs</kbd></dt>
<dd><p>If this is set, during ensembling scores from different models will be combined by averaging their raw probabilities and then taking the log. Otherwise, the log probabilities will be averaged directly. Necessary for models whose output layers can assign zero probability.</p>
<p>Default: False</p>
</dd>
<dt><kbd>--lang_pair, -lang_pair</kbd></dt>
<dd><p>language pair to translate</p>
</dd>
</dl>
</div>
<div class="section" id="Data">
<h2>Data<a class="headerlink" href="#Data" title="Permalink to this headline">Â¶</a></h2>
<dl class="option-list">
<dt><kbd>--data_type, -data_type</kbd></dt>
<dd><p>Type of the source input. Options: [text].</p>
<p>Default: âtextâ</p>
</dd>
<dt><kbd>--src, -src</kbd></dt>
<dd><p>Source sequence to decode (one line per sequence)</p>
</dd>
<dt><kbd>-src_feats, --src_feats</kbd></dt>
<dd><p>Source sequence features (dict format). Ex: {âfeat_0â: â../data.txt.feats0â, âfeat_1â: â../data.txt.feats1â}</p>
</dd>
<dt><kbd>--tgt, -tgt</kbd></dt>
<dd><p>True target sequence (optional)</p>
</dd>
<dt><kbd>--shard_size, -shard_size</kbd></dt>
<dd><p>Divide src and tgt (if applicable) into smaller multiple src and tgt files, then build shards, each shard will have opts.shard_size samples except last shard. shard_size=0 means no segmentation shard_size&gt;0 means segment dataset into multiple shards, each shard has shard_size samples</p>
<p>Default: 10000</p>
</dd>
<dt><kbd>--output, -output</kbd></dt>
<dd><p>Path to output the predictions (each line will be the decoded sequence</p>
<p>Default: âpred.txtâ</p>
</dd>
<dt><kbd>--report_align, -report_align</kbd></dt>
<dd><p>Report alignment for each translation.</p>
<p>Default: False</p>
</dd>
<dt><kbd>--report_time, -report_time</kbd></dt>
<dd><p>Report some translation time metrics</p>
<p>Default: False</p>
</dd>
</dl>
</div>
<div class="section" id="Beam Search">
<h2>Beam Search<a class="headerlink" href="#Beam Search" title="Permalink to this headline">Â¶</a></h2>
<dl class="option-list">
<dt><kbd>--beam_size, -beam_size</kbd></dt>
<dd><p>Beam size</p>
<p>Default: 5</p>
</dd>
<dt><kbd>--ratio, -ratio</kbd></dt>
<dd><p>Ratio based beam stop condition</p>
<p>Default: -0.0</p>
</dd>
</dl>
</div>
<div class="section" id="Random Sampling">
<h2>Random Sampling<a class="headerlink" href="#Random Sampling" title="Permalink to this headline">Â¶</a></h2>
<dl class="option-list">
<dt><kbd>--random_sampling_topk, -random_sampling_topk</kbd></dt>
<dd><p>Set this to -1 to do random sampling from full distribution. Set this to value k&gt;1 to do random sampling restricted to the k most likely next tokens. Set this to 1 to use argmax.</p>
<p>Default: 0</p>
</dd>
<dt><kbd>--random_sampling_topp, -random_sampling_topp</kbd></dt>
<dd><p>Probability for top-p/nucleus sampling. Restrict tokens to the most likely until the cumulated probability is over p. In range [0, 1]. <a class="reference external" href="https://arxiv.org/abs/1904.09751">https://arxiv.org/abs/1904.09751</a></p>
<p>Default: 0.0</p>
</dd>
<dt><kbd>--random_sampling_temp, -random_sampling_temp</kbd></dt>
<dd><p>If doing random sampling, divide the logits by this before computing softmax during decoding.</p>
<p>Default: 1.0</p>
</dd>
<dt><kbd>--beam_size, -beam_size</kbd></dt>
<dd><p>Beam size</p>
<p>Default: 5</p>
</dd>
</dl>
</div>
<div class="section" id="Reproducibility">
<h2>Reproducibility<a class="headerlink" href="#Reproducibility" title="Permalink to this headline">Â¶</a></h2>
<dl class="option-list">
<dt><kbd>--seed, -seed</kbd></dt>
<dd><p>Set random seed used for better reproducibility between experiments.</p>
<p>Default: -1</p>
</dd>
</dl>
</div>
<div class="section" id="Penalties">
<h2>Penalties<a class="headerlink" href="#Penalties" title="Permalink to this headline">Â¶</a></h2>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Coverage Penalty is not available in sampling.</p>
</div>
<dl class="option-list">
<dt><kbd>--length_penalty, -length_penalty</kbd></dt>
<dd><p>Possible choices: none, wu, avg</p>
<p>Length Penalty to use.</p>
<p>Default: ânoneâ</p>
</dd>
<dt><kbd>--alpha, -alpha</kbd></dt>
<dd><p>Google NMT length penalty parameter (higher = longer generation)</p>
<p>Default: 0.0</p>
</dd>
<dt><kbd>--coverage_penalty, -coverage_penalty</kbd></dt>
<dd><p>Possible choices: none, wu, summary</p>
<p>Coverage Penalty to use. Only available in beam search.</p>
<p>Default: ânoneâ</p>
</dd>
<dt><kbd>--beta, -beta</kbd></dt>
<dd><p>Coverage penalty parameter</p>
<p>Default: -0.0</p>
</dd>
<dt><kbd>--stepwise_penalty, -stepwise_penalty</kbd></dt>
<dd><p>Apply coverage penalty at every decoding step. Helpful for summary penalty.</p>
<p>Default: False</p>
</dd>
</dl>
</div>
<div class="section" id="Decoding tricks">
<h2>Decoding tricks<a class="headerlink" href="#Decoding tricks" title="Permalink to this headline">Â¶</a></h2>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>Following options can be used to limit the decoding length or content.</p>
</div>
<dl class="option-list">
<dt><kbd>--min_length, -min_length</kbd></dt>
<dd><p>Minimum prediction length</p>
<p>Default: 0</p>
</dd>
<dt><kbd>--max_length, -max_length</kbd></dt>
<dd><p>Maximum prediction length.</p>
<p>Default: 100</p>
</dd>
<dt><kbd>--max_sent_length, -max_sent_length</kbd></dt>
<dd><p>Deprecated, use <cite>-max_length</cite> instead</p>
</dd>
<dt><kbd>--block_ngram_repeat, -block_ngram_repeat</kbd></dt>
<dd><p>Block repetition of ngrams during decoding.</p>
<p>Default: 0</p>
</dd>
<dt><kbd>--ignore_when_blocking, -ignore_when_blocking</kbd></dt>
<dd><p>Ignore these strings when blocking repeats. You want to block sentence delimiters.</p>
<p>Default: []</p>
</dd>
<dt><kbd>--replace_unk, -replace_unk</kbd></dt>
<dd><p>Replace the generated UNK tokens with the source token that had highest attention weight. If phrase_table is provided, it will look up the identified source token and give the corresponding target token. If it is not provided (or the identified source token does not exist in the table), then it will copy the source token.</p>
<p>Default: False</p>
</dd>
<dt><kbd>--ban_unk_token, -ban_unk_token</kbd></dt>
<dd><p>Prevent unk token generation by setting unk proba to 0</p>
<p>Default: False</p>
</dd>
<dt><kbd>--phrase_table, -phrase_table</kbd></dt>
<dd><p>If phrase_table is provided (with replace_unk), it will look up the identified source token and give the corresponding target token. If it is not provided (or the identified source token does not exist in the table), then it will copy the source token.</p>
<p>Default: ââ</p>
</dd>
</dl>
</div>
<div class="section" id="Logging">
<h2>Logging<a class="headerlink" href="#Logging" title="Permalink to this headline">Â¶</a></h2>
<dl class="option-list">
<dt><kbd>--log_file, -log_file</kbd></dt>
<dd><p>Output logs to a file under this path.</p>
<p>Default: ââ</p>
</dd>
<dt><kbd>--structured_log_file, -structured_log_file</kbd></dt>
<dd><p>Output machine-readable structured logs to a file under this path.</p>
<p>Default: ââ</p>
</dd>
<dt><kbd>--log_file_level, -log_file_level</kbd></dt>
<dd><p>Possible choices: CRITICAL, ERROR, WARNING, INFO, DEBUG, NOTSET, 50, 40, 30, 20, 10, 0</p>
<p>Default: â0â</p>
</dd>
<dt><kbd>--verbose, -verbose</kbd></dt>
<dd><p>Print scores and predictions for each sentence</p>
<p>Default: False</p>
</dd>
<dt><kbd>--attn_debug, -attn_debug</kbd></dt>
<dd><p>Print best attn for each word</p>
<p>Default: False</p>
</dd>
<dt><kbd>--align_debug, -align_debug</kbd></dt>
<dd><p>Print best align for each word</p>
<p>Default: False</p>
</dd>
<dt><kbd>--dump_beam, -dump_beam</kbd></dt>
<dd><p>File to dump beam information to.</p>
<p>Default: ââ</p>
</dd>
<dt><kbd>--n_best, -n_best</kbd></dt>
<dd><p>If verbose is set, will output the n_best decoded sentences</p>
<p>Default: 1</p>
</dd>
</dl>
</div>
<div class="section" id="Efficiency">
<h2>Efficiency<a class="headerlink" href="#Efficiency" title="Permalink to this headline">Â¶</a></h2>
<dl class="option-list">
<dt><kbd>--batch_size, -batch_size</kbd></dt>
<dd><p>Batch size</p>
<p>Default: 30</p>
</dd>
<dt><kbd>--batch_type, -batch_type</kbd></dt>
<dd><p>Possible choices: sents, tokens</p>
<p>Batch grouping for batch_size. Standard is sents. Tokens will do dynamic batching</p>
<p>Default: âsentsâ</p>
</dd>
<dt><kbd>--gpu, -gpu</kbd></dt>
<dd><p>Device to run on</p>
<p>Default: -1</p>
</dd>
<dt><kbd>-transforms, --transforms</kbd></dt>
<dd><p>Possible choices: prefix, denoising, filtertoolong, filterwordratio, filterrepetitions, filterterminalpunct, filternonzeronumerals, filterfeats, inferfeats, switchout, tokendrop, tokenmask, sentencepiece, bpe, onmt_tokenize</p>
<p>Default transform pipeline to apply to data.</p>
<p>Default: []</p>
</dd>
<dt><kbd>--src_prefix, -src_prefix</kbd></dt>
<dd><p>The encoder prefix, i.e. language selector token</p>
<p>Default: ââ</p>
</dd>
<dt><kbd>--tgt_prefix, -tgt_prefix</kbd></dt>
<dd><p>The decoder prefix (FIXME: does not work, but must be set nevertheless)</p>
<p>Default: ââ</p>
</dd>
</dl>
</div>
<div class="section" id="Transform/Denoising AE">
<h2>Transform/Denoising AE<a class="headerlink" href="#Transform/Denoising AE" title="Permalink to this headline">Â¶</a></h2>
<dl class="option-list">
<dt><kbd>--permute_sent_ratio, -permute_sent_ratio</kbd></dt>
<dd><p>Permute this proportion of sentences (boundaries defined by [â.â, â?â, â!â]) in all inputs.</p>
<p>Default: 0.0</p>
</dd>
<dt><kbd>--rotate_ratio, -rotate_ratio</kbd></dt>
<dd><p>Rotate this proportion of inputs.</p>
<p>Default: 0.0</p>
</dd>
<dt><kbd>--insert_ratio, -insert_ratio</kbd></dt>
<dd><p>Insert this percentage of additional random tokens.</p>
<p>Default: 0.0</p>
</dd>
<dt><kbd>--random_ratio, -random_ratio</kbd></dt>
<dd><p>Instead of using &lt;mask&gt;, use random token this often. Incompatible with MASS</p>
<p>Default: 0.0</p>
</dd>
<dt><kbd>--mask_ratio, -mask_ratio</kbd></dt>
<dd><p>Fraction of words/subwords that will be masked.</p>
<p>Default: 0.0</p>
</dd>
<dt><kbd>--mask_length, -mask_length</kbd></dt>
<dd><p>Possible choices: subword, word, span-poisson</p>
<p>Length of masking window to apply.</p>
<p>Default: âsubwordâ</p>
</dd>
<dt><kbd>--poisson_lambda, -poisson_lambda</kbd></dt>
<dd><p>Lambda for Poisson distribution to sample span length if <cite>-mask_length</cite> set to span-poisson.</p>
<p>Default: 3.0</p>
</dd>
<dt><kbd>--replace_length, -replace_length</kbd></dt>
<dd><p>Possible choices: -1, 0, 1</p>
<p>When masking N tokens, replace with 0, 1, or N tokens. (use -1 for N)</p>
<p>Default: -1</p>
</dd>
<dt><kbd>--denoising_objective</kbd></dt>
<dd><p>Possible choices: bart, mass</p>
<p>choose between BART-style or MASS-style denoising objectives</p>
<p>Default: âbartâ</p>
</dd>
</dl>
</div>
<div class="section" id="Transform/Filter">
<h2>Transform/Filter<a class="headerlink" href="#Transform/Filter" title="Permalink to this headline">Â¶</a></h2>
<dl class="option-list">
<dt><kbd>--src_seq_length, -src_seq_length</kbd></dt>
<dd><p>Maximum source sequence length.</p>
<p>Default: 200</p>
</dd>
<dt><kbd>--tgt_seq_length, -tgt_seq_length</kbd></dt>
<dd><p>Maximum target sequence length.</p>
<p>Default: 200</p>
</dd>
</dl>
</div>
<div class="section" id="Transform/Filter_repeat1">
<h2>Transform/Filter<a class="headerlink" href="#Transform/Filter_repeat1" title="Permalink to this headline">Â¶</a></h2>
<dl class="option-list">
<dt><kbd>--word_ratio_threshold, -word_ratio_threshold</kbd></dt>
<dd><p>Threshold for discarding sentences based on word ratio.</p>
<p>Default: 3</p>
</dd>
</dl>
</div>
<div class="section" id="Transform/Filter_repeat2">
<h2>Transform/Filter<a class="headerlink" href="#Transform/Filter_repeat2" title="Permalink to this headline">Â¶</a></h2>
<dl class="option-list">
<dt><kbd>--rep_threshold, -rep_threshold</kbd></dt>
<dd><p>Number of times the substring is repeated.</p>
<p>Default: 2</p>
</dd>
<dt><kbd>--rep_min_len, -rep_min_len</kbd></dt>
<dd><p>Minimum length of the repeated pattern.</p>
<p>Default: 3</p>
</dd>
<dt><kbd>--rep_max_len, -rep_max_len</kbd></dt>
<dd><p>Maximum length of the repeated pattern.</p>
<p>Default: 100</p>
</dd>
</dl>
</div>
<div class="section" id="Transform/Filter_repeat3">
<h2>Transform/Filter<a class="headerlink" href="#Transform/Filter_repeat3" title="Permalink to this headline">Â¶</a></h2>
<dl class="option-list">
<dt><kbd>--punct_threshold, -punct_threshold</kbd></dt>
<dd><p>Minimum penalty score for discarding sentences based on their terminal punctuation signs</p>
<p>Default: -2</p>
</dd>
</dl>
</div>
<div class="section" id="Transform/Filter_repeat4">
<h2>Transform/Filter<a class="headerlink" href="#Transform/Filter_repeat4" title="Permalink to this headline">Â¶</a></h2>
<dl class="option-list">
<dt><kbd>--nonzero_threshold, -nonzero_threshold</kbd></dt>
<dd><p>Threshold for discarding sentences based on numerals between the segments with zeros removed</p>
<p>Default: 0.5</p>
</dd>
</dl>
</div>
<div class="section" id="Transform/InferFeats">
<h2>Transform/InferFeats<a class="headerlink" href="#Transform/InferFeats" title="Permalink to this headline">Â¶</a></h2>
<dl class="option-list">
<dt><kbd>--reversible_tokenization, -reversible_tokenization</kbd></dt>
<dd><p>Possible choices: joiner, spacer</p>
<p>Type of reversible tokenization applied on the tokenizer.</p>
<p>Default: âjoinerâ</p>
</dd>
<dt><kbd>--prior_tokenization, -prior_tokenization</kbd></dt>
<dd><p>Whether the input has already been tokenized.</p>
<p>Default: False</p>
</dd>
</dl>
</div>
<div class="section" id="Transform/SwitchOut">
<h2>Transform/SwitchOut<a class="headerlink" href="#Transform/SwitchOut" title="Permalink to this headline">Â¶</a></h2>
<dl class="option-list">
<dt><kbd>-switchout_temperature, --switchout_temperature</kbd></dt>
<dd><p>Sampling temperature for SwitchOut. <span class="math notranslate nohighlight">\(\tau^{-1}\)</span> in <a class="bibtex reference internal" href="../ref.html#dblp-journals-corr-abs-1808-07512" id="id1">[WPDN18]</a>. Smaller value makes data more diverse.</p>
<p>Default: 1.0</p>
</dd>
</dl>
</div>
<div class="section" id="Transform/Token_Drop">
<h2>Transform/Token_Drop<a class="headerlink" href="#Transform/Token_Drop" title="Permalink to this headline">Â¶</a></h2>
<dl class="option-list">
<dt><kbd>-tokendrop_temperature, --tokendrop_temperature</kbd></dt>
<dd><p>Sampling temperature for token deletion.</p>
<p>Default: 1.0</p>
</dd>
</dl>
</div>
<div class="section" id="Transform/Token_Mask">
<h2>Transform/Token_Mask<a class="headerlink" href="#Transform/Token_Mask" title="Permalink to this headline">Â¶</a></h2>
<dl class="option-list">
<dt><kbd>-tokenmask_temperature, --tokenmask_temperature</kbd></dt>
<dd><p>Sampling temperature for token masking.</p>
<p>Default: 1.0</p>
</dd>
</dl>
</div>
<div class="section" id="Transform/Subword/Common">
<h2>Transform/Subword/Common<a class="headerlink" href="#Transform/Subword/Common" title="Permalink to this headline">Â¶</a></h2>
<div class="admonition attention">
<p class="admonition-title">Attention</p>
<p>Common options shared by all subword transforms. Including options for indicate subword model path, <a class="reference external" href="https://arxiv.org/abs/1804.10959">Subword Regularization</a>/<a class="reference external" href="https://arxiv.org/abs/1910.13267">BPE-Dropout</a>, and <a class="reference external" href="https://github.com/rsennrich/subword-nmt#best-practice-advice-for-byte-pair-encoding-in-nmt">Vocabulary Restriction</a>.</p>
</div>
<dl class="option-list">
<dt><kbd>-src_subword_model, --src_subword_model</kbd></dt>
<dd><p>Path of subword model for src (or shared).</p>
</dd>
<dt><kbd>-tgt_subword_model, --tgt_subword_model</kbd></dt>
<dd><p>Path of subword model for tgt.</p>
</dd>
<dt><kbd>-src_subword_nbest, --src_subword_nbest</kbd></dt>
<dd><p>Number of candidates in subword regularization. Valid for unigram sampling, invalid for BPE-dropout. (source side)</p>
<p>Default: 1</p>
</dd>
<dt><kbd>-tgt_subword_nbest, --tgt_subword_nbest</kbd></dt>
<dd><p>Number of candidates in subword regularization. Valid for unigram sampling, invalid for BPE-dropout. (target side)</p>
<p>Default: 1</p>
</dd>
<dt><kbd>-src_subword_alpha, --src_subword_alpha</kbd></dt>
<dd><p>Smoothing parameter for sentencepiece unigram sampling, and dropout probability for BPE-dropout. (source side)</p>
<p>Default: 0</p>
</dd>
<dt><kbd>-tgt_subword_alpha, --tgt_subword_alpha</kbd></dt>
<dd><p>Smoothing parameter for sentencepiece unigram sampling, and dropout probability for BPE-dropout. (target side)</p>
<p>Default: 0</p>
</dd>
<dt><kbd>-src_subword_vocab, --src_subword_vocab</kbd></dt>
<dd><p>Path to the vocabulary file for src subword. Format: &lt;word&gt;     &lt;count&gt; per line.</p>
<p>Default: ââ</p>
</dd>
<dt><kbd>-tgt_subword_vocab, --tgt_subword_vocab</kbd></dt>
<dd><p>Path to the vocabulary file for tgt subword. Format: &lt;word&gt;     &lt;count&gt; per line.</p>
<p>Default: ââ</p>
</dd>
<dt><kbd>-src_vocab_threshold, --src_vocab_threshold</kbd></dt>
<dd><p>Only produce src subword in src_subword_vocab with frequency &gt;= src_vocab_threshold.</p>
<p>Default: 0</p>
</dd>
<dt><kbd>-tgt_vocab_threshold, --tgt_vocab_threshold</kbd></dt>
<dd><p>Only produce tgt subword in tgt_subword_vocab with frequency &gt;= tgt_vocab_threshold.</p>
<p>Default: 0</p>
</dd>
</dl>
</div>
<div class="section" id="Transform/Subword/ONMTTOK">
<h2>Transform/Subword/ONMTTOK<a class="headerlink" href="#Transform/Subword/ONMTTOK" title="Permalink to this headline">Â¶</a></h2>
<dl class="option-list">
<dt><kbd>-src_subword_type, --src_subword_type</kbd></dt>
<dd><p>Possible choices: none, sentencepiece, bpe</p>
<p>Type of subword model for src (or shared) in pyonmttok.</p>
<p>Default: ânoneâ</p>
</dd>
<dt><kbd>-tgt_subword_type, --tgt_subword_type</kbd></dt>
<dd><p>Possible choices: none, sentencepiece, bpe</p>
<p>Type of subword model for tgt in  pyonmttok.</p>
<p>Default: ânoneâ</p>
</dd>
<dt><kbd>-src_onmttok_kwargs, --src_onmttok_kwargs</kbd></dt>
<dd><p>Other pyonmttok options for src in dict string, except subword related options listed earlier.</p>
<p>Default: â{âmodeâ: ânoneâ}â</p>
</dd>
<dt><kbd>-tgt_onmttok_kwargs, --tgt_onmttok_kwargs</kbd></dt>
<dd><p>Other pyonmttok options for tgt in dict string, except subword related options listed earlier.</p>
<p>Default: â{âmodeâ: ânoneâ}â</p>
</dd>
</dl>
</div>
<div class="section" id="Source and Target Languages">
<h2>Source and Target Languages<a class="headerlink" href="#Source and Target Languages" title="Permalink to this headline">Â¶</a></h2>
<dl class="option-list">
<dt><kbd>--src_lang, -src_lang</kbd></dt>
<dd><p>The 2-character source language code</p>
</dd>
<dt><kbd>--tgt_lang, -tgt_lang</kbd></dt>
<dd><p>The 2-character target language code</p>
</dd>
<dt><kbd>--stack</kbd></dt>
<dd><p>The stack of modules to use. Use a yaml conf, for your own sanity</p>
</dd>
<dt><kbd>--output_model, -output_model</kbd></dt>
<dd><p>Path to the model output</p>
</dd>
</dl>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="server.html" class="btn btn-neutral float-right" title="Server" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="train.html" class="btn btn-neutral float-left" title="Train" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2023, HelsinkiNLP

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>